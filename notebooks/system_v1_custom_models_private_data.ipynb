{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./resources/System_v1_training_header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a demonstration on how to train a custom temporary crop extent model based on your own reference data and how to apply the resulting model to generate a custom temporary crop extent map.\n",
    "\n",
    "# Content\n",
    "\n",
    "- [Before you start](#before-you-start)\n",
    "- [1. Define region of interest](#1.-Define-a-region-of-interest)\n",
    "- [2. Check existing in-situ reference data](#2.-Check-existing-in-situ-reference-data)\n",
    "- [3. Prepare own reference data](#3.-Prepare-own-reference-data)\n",
    "- [4. Extract required model inputs](#4.-Extract-required-model-inputs)\n",
    "- [5. Train custom classification model](#5.-Train-custom-classification-model)\n",
    "- [6. Deploy custom model](#6.-Deploy-custom-model)\n",
    "- [7. Generate a map](#7.-Generate-a-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "In order to run this notebook, you need to create an account on:\n",
    "\n",
    "- The Copernicus Data Space Ecosystem (CDSE)\n",
    "--> by completing the form [HERE](https://identity.dataspace.copernicus.eu/auth/realms/CDSE/login-actions/registration?client_id=cdse-public&tab_id=eRKGqDvoYI0)\n",
    "\n",
    "- VITO's Terrascope platform\n",
    "--> by completing the form [HERE](https://sso.terrascope.be/auth/realms/terrascope/login-actions/registration?client_id=drupal-terrascope&tab_id=irBzckp2aDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix access to utils script avoiding this import\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    \"/home/jeroendegerickx/git/worldcereal/worldcereal-classification/notebooks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define a region of interest\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest.\n",
    "When finished, execute the second cell to store the coordinates of your region of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164f96c8499b4c818160819f7079202d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[51.1872, 5.1154], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoo…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from worldcereal.utils.map import get_ui_map\n",
    "\n",
    "m, dc = get_ui_map()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your area of interest: (110.139282, -7.383168, 110.147519, -7.373634)\n",
      "Area of processing extent: 0.96 km²\n"
     ]
    }
   ],
   "source": [
    "# retrieve bounding box from drawn rectangle\n",
    "from worldcereal.utils.map import get_bbox_from_draw\n",
    "\n",
    "spatial_extent, bbox, poly = get_bbox_from_draw(dc)\n",
    "\n",
    "# TODO: relax processing area limit but raise a warning containing an estimate on processsing credits consumption for large areas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Check existing in situ reference data\n",
    "\n",
    "We query the database of existing training data, which is stored as a parquet file on a Cloudferro S3 bucket..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying a buffer of 50.0 km to the selected area ...\n",
      "Querying WorldCereal global database ...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Query interrupted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m query_worldcereal_samples\n\u001b[0;32m----> 3\u001b[0m public_df \u001b[38;5;241m=\u001b[39m \u001b[43mquery_worldcereal_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_cropland\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m public_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/git/worldcereal/worldcereal-classification/notebooks/utils.py:139\u001b[0m, in \u001b[0;36mquery_worldcereal_samples\u001b[0;34m(bbox_poly, buffer, filter_cropland)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124m        set s3_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3.waw3-1.cloudferro.com\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124m        set enable_progress_bar=false;\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124m        where original_data.h3_l5_cell in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh3_cells_lst\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 139\u001b[0m public_df_raw \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdf()\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing selected samples ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m public_df \u001b[38;5;241m=\u001b[39m process_parquet(public_df_raw)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Query interrupted"
     ]
    }
   ],
   "source": [
    "from utils import query_worldcereal_samples\n",
    "\n",
    "public_df = query_worldcereal_samples(poly, buffer=50000, filter_cropland=False)\n",
    "public_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare own reference data\n",
    "\n",
    "The idea of this section is that we prepare additional training data for our custom model based on a user-provided dataset. Required ingredients are:\n",
    "- actual samples from the private dataset, extracted from the WorldCereal Reference Data Module (RDM)\n",
    "- for all these samples, we need the required EO and auxilliary data needed to train the custom model. These data will be extracted through an OpenEO extraction workflow.\n",
    "\n",
    "First we check which publicly available reference datasets are available in the RDM near our region of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ewoc-rdm-api.iiasa.ac.at/collections/search?Bbox=107.89349378970118&Bbox=-9.604179528638747&Bbox=112.3933072102988&Bbox=-5.141370619541715\n",
      "The following collections intersect with your AOI:\n",
      "\n",
      "Collection 1: 2023idnvitocampaignpoly110 of type Polygon containing 335 samples\n",
      "\n",
      "Collection 2: 2023idnvitomanualpoint100 of type Point containing 1290 samples\n"
     ]
    }
   ],
   "source": [
    "from utils import rdm_collection_request\n",
    "\n",
    "col_ids = rdm_collection_request(poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have uploaded a private dataset (2022idnvitopoint100) to the WorldCereal Reference Data Module (RDM).\n",
    "In order to retrieve our private dataset from the RDM, we need to login with our Terrascope login.\n",
    "\n",
    "In the following cell, we :\n",
    "- log in to Terrascope to be able to discover this dataset\n",
    "- verify which collections (including private ones) intersect with our region of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ewoc-rdm-api.iiasa.ac.at/collections/search?Bbox=107.79602078970119&Bbox=-9.515884550205376&Bbox=112.30407721029881&Bbox=-5.056290330117706\n",
      "The following collections intersect with your AOI:\n",
      "\n",
      "Collection 1: 2023idnvitocampaignpoly110 of type Polygon containing 335 samples\n",
      "\n",
      "Collection 2: 2022idnvitopoint100 of type Point containing 1291 samples\n",
      "\n",
      "Collection 3: 2023idnvitomanualpoint100 of type Point containing 1290 samples\n",
      "https://ewoc-rdm-api.iiasa.ac.at/collections/2022idnvitopoint100/items?Bbox=107.79602078970119&Bbox=-9.515884550205376&Bbox=112.30407721029881&Bbox=-5.056290330117706&MaxResultCount=1000\n",
      "Got a total of 372 reference points\n"
     ]
    }
   ],
   "source": [
    "from utils import terrascope_login, rdm_collection_request, rdm_features_request\n",
    "from pathlib import Path\n",
    "\n",
    "token = terrascope_login()\n",
    "col_ids = rdm_collection_request(poly, token)\n",
    "\n",
    "\n",
    "samples = rdm_features_request(\n",
    "    poly, col_ids=[\"2022idnvitopoint100\"], headers=token, max_items=1000\n",
    ")\n",
    "\n",
    "# TODO: the following action should actually be done automatically in the RDM? --> whenever a user uploads a private dataset, all samples should be marked as \"to be extracted\"?\n",
    "# We mark all samples as to be extracted\n",
    "samples[\"extract\"] = [1] * len(samples)\n",
    "\n",
    "# TODO: make output path customizable\n",
    "features_file = \"/vitodata/worldcereal/test/demo_idn/features.parquet\"\n",
    "Path(features_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "samples.to_parquet(features_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we download for all collections of interest all samples closer than 250 km from our area of interest and save that to a .parquet file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter here for which collections you would like to extract samples:\n",
    "collections_to_extract = [\"2022idnvitopoint100\"]\n",
    "\n",
    "# The following function requests all samples from the RDM\n",
    "# TODO: make sure we can request more than 1000 samples --> add pagination (question was raised to Santosh)\n",
    "samples = rdm_features_request(\n",
    "    poly, col_ids=collections_to_extract, headers=token, max_items=1000\n",
    ")\n",
    "\n",
    "# TODO: the following action should actually be done automatically in the RDM? --> whenever a user uploads a private dataset, all samples should be marked as \"to be extracted\"?\n",
    "# We mark all samples as to be extracted\n",
    "samples[\"extract\"] = [1] * len(samples)\n",
    "\n",
    "# TODO: make output path customizable\n",
    "features_file = \"/vitodata/worldcereal/test/demo_idn/features.parquet\"\n",
    "Path(features_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "samples.to_parquet(features_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start point extractions for all these acquired samples through OpenEO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "point_extractions() missing 1 required positional argument: 'output_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      4\u001b[0m output_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/vitodata/worldcereal/test/demo_idn/extractions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mpoint_extractions\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: point_extractions() missing 1 required positional argument: 'output_path'"
     ]
    }
   ],
   "source": [
    "# TODO: import point extractions from scripts > extractions > point_extractions.py\n",
    "# (we need to make sure we have a similar function in there which can be imported here)\n",
    "# OR move this functionality to src\n",
    "# and remove the point_extractions functionality from utils\n",
    "\n",
    "# TODO: issue warning whenever user is about to launch A LOT OF extractions!\n",
    "\n",
    "from utils import point_extractions\n",
    "\n",
    "# TODO: make output path customizable\n",
    "output_path = Path(\"/vitodata/worldcereal/test/demo_idn/extractions\")\n",
    "point_extractions(features_file, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point extractions have been splitted automatically in multiple jobs. Here, we fetch all extractions and merge them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'feature_index', 'S2-L2A-B02', 'S2-L2A-B03', 'S2-L2A-B04',\n",
       "       'S2-L2A-B05', 'S2-L2A-B06', 'S2-L2A-B07', 'S2-L2A-B08', 'S2-L2A-B11',\n",
       "       'S2-L2A-B12', 'S1-SIGMA0-VH', 'S1-SIGMA0-VV', 'COP-DEM',\n",
       "       'AGERA5-PRECIP', 'AGERA5-TMEAN', 'geometry', 'irrigation_status',\n",
       "       'extract', 'sample_id', 'quality_score_lc', 'tile', 'valid_time',\n",
       "       'quality_score_ct', 'ewoc_code', 'h3_l3_cell'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import fetch_point_extractions\n",
    "\n",
    "dfs = fetch_point_extractions(output_path)\n",
    "\n",
    "# TODO: first, each individual pandas dataframe needs to be processed into a format that can be used for training\n",
    "# i.e. one row should represent a single sample\n",
    "# because if you would merge these dataframes together before processing them, the \"feature_index\" will be wrong as it is set for\n",
    "# each individual dataframe\n",
    "\n",
    "processed_dfs = [process_df(df) for df in dfs]\n",
    "private_df = pd.concat(processed_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we merge the public data with our private data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([public_df, private_df], axis=0, ignore_index=True)\n",
    "print(f\"Total number of samples: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extract required model inputs\n",
    "\n",
    "Here we prepare presto features for each sample by using a model pretrained on WorldCereal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_inputs_outputs\n",
    "\n",
    "encodings, targets = get_inputs_outputs(public_df, task_type=\"cropland\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train custom classification model\n",
    "We train a catboost model and upload this model to artifactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_classifier\n",
    "\n",
    "custom_model, report = train_classifier(encodings, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Deploy custom model\n",
    "\n",
    "Once trained, we have to upload our model to the cloud so it can be used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import deploy_model\n",
    "\n",
    "model_url = deploy_model(custom_model, pattern=\"demo_cropland\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generate a map\n",
    "\n",
    "Using our custom model, we generate a map for our region of interest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.job import WorldCerealProduct, generate_map, CropLandParameters\n",
    "from openeo_gfmap import TemporalContext\n",
    "\n",
    "# Set temporal range to generate product\n",
    "temporal_extent = TemporalContext(\n",
    "    start_date=\"2021-11-01\",\n",
    "    end_date=\"2022-10-31\",\n",
    ")\n",
    "\n",
    "# Initializes default parameters\n",
    "parameters = CropLandParameters()\n",
    "\n",
    "# Change the URL to the classification model\n",
    "parameters.classifier_parameters.classifier_url = model_url\n",
    "\n",
    "# Launch the job\n",
    "job_results = generate_map(\n",
    "    spatial_extent,\n",
    "    temporal_extent,\n",
    "    output_path=\"./cropland_map.tif\",\n",
    "    product_type=WorldCerealProduct.CROPLAND,\n",
    "    croptype_parameters=parameters,\n",
    "    out_format=\"GTiff\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
