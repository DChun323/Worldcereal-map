{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./resources/System_v1_training_header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a demonstration on how to train custom crop type models based on your own reference data and how to apply the resulting model to generate a custom crop type map.\n",
    "\n",
    "# Content\n",
    "\n",
    "- [Before you start](#before-you-start)\n",
    "- [1. Define region of interest](#1.-Define-a-region-of-interest)\n",
    "- [2. Check public in-situ reference data](#2.-Check-public-in-situ-reference-data)\n",
    "- [3. Prepare own reference data](#3.-Prepare-own-reference-data)\n",
    "- [4. Extract required model inputs](#4.-Extract-required-model-inputs)\n",
    "- [5. Train custom classification model](#5.-Train-custom-classification-model)\n",
    "- [6. Generate a map](#6.-Generate-a-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "In order to run this notebook, you need to create an account on:\n",
    "\n",
    "- The Copernicus Data Space Ecosystem (CDSE)\n",
    "--> by completing the form [HERE](https://identity.dataspace.copernicus.eu/auth/realms/CDSE/login-actions/registration?client_id=cdse-public&tab_id=eRKGqDvoYI0)\n",
    "\n",
    "- VITO's Terrascope platform\n",
    "--> by completing the form [HERE](https://sso.terrascope.be/auth/realms/terrascope/login-actions/registration?client_id=drupal-terrascope&tab_id=irBzckp2aDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import get_ui_map\n",
    "RDM_API = \"https://ewoc-rdm-api.iiasa.ac.at\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define a region of interest\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest.\n",
    "When finished, execute the second cell to store the coordinates of your region of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c4b26d7e72477d87c25eaa3aa188d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[51.1872, 5.1154], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoo…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, dc = get_ui_map()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your area of interest: (3.995798, 50.679638, 6.029137, 51.487085)\n"
     ]
    }
   ],
   "source": [
    "# retrieve bounding box from drawn rectangle\n",
    "from utils import get_bbox_from_draw\n",
    "\n",
    "bbox, poly = get_bbox_from_draw(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Check public in situ reference data\n",
    "\n",
    "Here we do a series of requests to the RDM API to retrieve the collections and samples overlapping our bbox..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‼ The following snippet does not query the RDM API, but parquet file on Cloudferro bucket with Phase I extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying WorldCereal global database ...\n",
      "Processing selected samples ...\n",
      "Extracted and processed 18551 samples from global database.\n"
     ]
    }
   ],
   "source": [
    "from utils import query_worldcereal_samples\n",
    "\n",
    "public_df = query_worldcereal_samples(poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Prepare own reference data\n",
    "\n",
    "Include some guidelines on how to upload user dataset to RDM (using the UI) and requesting those user samples through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = public_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Select desired crops for prediction\n",
    "\n",
    "Crops with ticked checkboxes will be included in the prediction. All the crops that are not selected will be grouped under the \"other_crop\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a24c8f9446443f7a8fdb5351ea7223a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='maize (11284 samples)'), Checkbox(value=False, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import pick_croptypes\n",
    "from IPython.display import display\n",
    "\n",
    "checkbox, checkbox_widgets = pick_croptypes(merged_df, samples_threshold=100)\n",
    "display(checkbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_class\n",
       "maize       11284\n",
       "other        5823\n",
       "potatoes     1444\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_custom_labels\n",
    "\n",
    "merged_df = get_custom_labels(merged_df, checkbox_widgets)\n",
    "merged_df['custom_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extract required model inputs\n",
    "\n",
    "Here we launch point extractions for all samples intersecting our bbox resulting in a set of parquet files.\n",
    "\n",
    "We collect all these inputs and prepare presto features for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_inputs_outputs\n",
    "\n",
    "encodings, targets = get_inputs_outputs(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train custom classification model\n",
    "We train a catboost model and upload this model to artifactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0683194\ttest: 1.0696515\tbest: 1.0696515 (0)\ttotal: 83.1ms\tremaining: 11m 5s\n",
      "25:\tlearn: 0.7202533\ttest: 0.7443568\tbest: 0.7443568 (25)\ttotal: 1.95s\tremaining: 9m 58s\n",
      "50:\tlearn: 0.5995132\ttest: 0.6449592\tbest: 0.6449592 (50)\ttotal: 3.55s\tremaining: 9m 13s\n",
      "75:\tlearn: 0.5282046\ttest: 0.5954327\tbest: 0.5954327 (75)\ttotal: 4.76s\tremaining: 8m 16s\n",
      "100:\tlearn: 0.4821101\ttest: 0.5717230\tbest: 0.5717230 (100)\ttotal: 5.97s\tremaining: 7m 46s\n",
      "125:\tlearn: 0.4500074\ttest: 0.5565383\tbest: 0.5565383 (125)\ttotal: 7.07s\tremaining: 7m 22s\n",
      "150:\tlearn: 0.4218480\ttest: 0.5436805\tbest: 0.5436805 (150)\ttotal: 8.14s\tremaining: 7m 3s\n",
      "175:\tlearn: 0.3956958\ttest: 0.5340225\tbest: 0.5340225 (175)\ttotal: 9.19s\tremaining: 6m 48s\n",
      "200:\tlearn: 0.3749655\ttest: 0.5264903\tbest: 0.5264903 (200)\ttotal: 10.3s\tremaining: 6m 38s\n",
      "225:\tlearn: 0.3560403\ttest: 0.5207208\tbest: 0.5207208 (225)\ttotal: 11.3s\tremaining: 6m 26s\n",
      "250:\tlearn: 0.3388021\ttest: 0.5164177\tbest: 0.5164177 (250)\ttotal: 12.2s\tremaining: 6m 17s\n",
      "275:\tlearn: 0.3229028\ttest: 0.5129313\tbest: 0.5129313 (275)\ttotal: 13.1s\tremaining: 6m 6s\n",
      "300:\tlearn: 0.3079165\ttest: 0.5096829\tbest: 0.5096829 (300)\ttotal: 13.9s\tremaining: 5m 56s\n",
      "325:\tlearn: 0.2943228\ttest: 0.5080780\tbest: 0.5080780 (325)\ttotal: 14.8s\tremaining: 5m 49s\n",
      "350:\tlearn: 0.2815721\ttest: 0.5063448\tbest: 0.5062854 (349)\ttotal: 15.7s\tremaining: 5m 42s\n",
      "375:\tlearn: 0.2702204\ttest: 0.5050259\tbest: 0.5048637 (370)\ttotal: 16.6s\tremaining: 5m 36s\n",
      "400:\tlearn: 0.2598794\ttest: 0.5040100\tbest: 0.5040100 (400)\ttotal: 17.5s\tremaining: 5m 31s\n",
      "425:\tlearn: 0.2498469\ttest: 0.5037819\tbest: 0.5037395 (414)\ttotal: 18.5s\tremaining: 5m 28s\n",
      "450:\tlearn: 0.2413304\ttest: 0.5033510\tbest: 0.5033221 (449)\ttotal: 19.5s\tremaining: 5m 26s\n",
      "475:\tlearn: 0.2333148\ttest: 0.5029534\tbest: 0.5027008 (463)\ttotal: 20.8s\tremaining: 5m 29s\n",
      "500:\tlearn: 0.2258686\ttest: 0.5031820\tbest: 0.5027008 (463)\ttotal: 22.4s\tremaining: 5m 34s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.5027007696\n",
      "bestIteration = 463\n",
      "\n",
      "Shrink model to first 464 iterations.\n"
     ]
    }
   ],
   "source": [
    "from utils import train_classifier\n",
    "\n",
    "custom_model, report = train_classifier(encodings, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       maize       0.92      0.89      0.90      3386\n",
      "       other       0.80      0.80      0.80      1747\n",
      "    potatoes       0.58      0.71      0.64       433\n",
      "\n",
      "    accuracy                           0.85      5566\n",
      "   macro avg       0.77      0.80      0.78      5566\n",
      "weighted avg       0.85      0.85      0.85      5566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Deploy custom model\n",
    "\n",
    "Once trained, we have to upload our model to the cloud so it can be used for inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generate a map\n",
    "\n",
    "Using our custom model, we generate a map for our region of interest..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
