{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./resources/System_v1_training_header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a demonstration on how to train custom crop type models based on your own reference data and how to apply the resulting model to generate a custom crop type map.\n",
    "\n",
    "# Content\n",
    "\n",
    "- [Before you start](#before-you-start)\n",
    "- [1. Define region of interest](#1.-Define-a-region-of-interest)\n",
    "- [2. Check public in-situ reference data](#2.-Check-public-in-situ-reference-data)\n",
    "- [3. Prepare own reference data](#3.-Prepare-own-reference-data)\n",
    "- [4. Extract required model inputs](#4.-Extract-required-model-inputs)\n",
    "- [5. Train custom classification model](#5.-Train-custom-classification-model)\n",
    "- [6. Generate a map](#6.-Generate-a-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "In order to run this notebook, you need to create an account on:\n",
    "\n",
    "- The Copernicus Data Space Ecosystem (CDSE)\n",
    "--> by completing the form [HERE](https://identity.dataspace.copernicus.eu/auth/realms/CDSE/login-actions/registration?client_id=cdse-public&tab_id=eRKGqDvoYI0)\n",
    "\n",
    "- VITO's Terrascope platform\n",
    "--> by completing the form [HERE](https://sso.terrascope.be/auth/realms/terrascope/login-actions/registration?client_id=drupal-terrascope&tab_id=irBzckp2aDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we import the necessary modules to run this notebook\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from shapely.geometry import shape, Polygon\n",
    "import xarray as xr\n",
    "\n",
    "import openeo\n",
    "from openeo_gfmap import BoundingBoxExtent, TemporalContext\n",
    "from openeo_gfmap.backend import Backend, BackendContext\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/worldcereal-classification/src')\n",
    "# sys.path.append('/home/cbutsko/Desktop/worldcereal-classification/src')\n",
    "\n",
    "from worldcereal.utils.map import (get_ui_map, _latlon_to_utm)\n",
    "from worldcereal.utils.refdata import _to_points\n",
    "from worldcereal.utils.wrapper import run_inference\n",
    "\n",
    "RDM_API = 'https://ewoc-rdm-api.iiasa.ac.at'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define a region of interest\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest.\n",
    "When finished, execute the second cell to store the coordinates of your region of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a98c4773a648c2a3096d25f421736f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[51.1872, 5.1154], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zooâ€¦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, dc = get_ui_map()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your area of interest: (4.511536, 51.12835, 5.24762, 51.312417)\n"
     ]
    }
   ],
   "source": [
    "# retrieve bounding box from drawn rectangle\n",
    "obj = dc.last_draw\n",
    "if obj.get('geometry') is not None:\n",
    "    poly = Polygon(shape(obj.get('geometry')))\n",
    "    bbox = poly.bounds\n",
    "else:\n",
    "    raise ValueError('Please first draw a rectangle '\n",
    "                     'on the map before proceeding.')\n",
    "print(f'Your area of interest: {bbox}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Check public in situ reference data\n",
    "\n",
    "Here we do a series of requests to the RDM API to retrieve the collections and samples overlapping our bbox..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¼ The following snippet does not query the RDM API, but parquet file on Cloudferro bucket with Phase I extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional imports\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import ipywidgets as widgets\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# added presto path the same way world cereal is added. right now it needs the branch inference-extension-to-parquet\n",
    "# should be changed to master once the branch is merged \n",
    "presto_repo_path = \"/home/cbutsko/Desktop/presto-worldcereal/\"\n",
    "sys.path.append(presto_repo_path)\n",
    "from presto.inference import get_presto_features, process_parquet\n",
    "from presto.presto import Presto\n",
    "from presto.dataset import WorldCerealLabelledDataset\n",
    "\n",
    "from presto.utils import DEFAULT_SEED, device\n",
    "\n",
    "# this path is hardcoded now ðŸ˜¥\n",
    "data_dir = \"/home/cbutsko/Desktop/worldcereal-classification/notebooks/resources\"\n",
    "with open(f\"{data_dir}/croptype_classes.json\") as f:\n",
    "    CLASS_MAPPINGS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure where to put these functions ðŸ˜¥\n",
    "def get_encodings_targets(\n",
    "    df: pd.DataFrame, presto_model, batch_size: int = 1024\n",
    ") -> [np.ndarray, np.ndarray]:\n",
    "\n",
    "    tds = WorldCerealLabelledDataset(df, target_function=lambda xx: xx[\"custom_class\"])\n",
    "    tdl = DataLoader(tds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    encoding_list, targets = [], []\n",
    "\n",
    "    for x, y, dw, latlons, month, variable_mask in tdl:\n",
    "        x_f, dw_f, latlons_f, month_f, variable_mask_f = [\n",
    "            t.to(device) for t in (x, dw, latlons, month, variable_mask)\n",
    "        ]\n",
    "        input_d = {\n",
    "            \"x\": x_f,\n",
    "            \"dynamic_world\": dw_f.long(),\n",
    "            \"latlons\": latlons_f,\n",
    "            \"mask\": variable_mask_f,\n",
    "            \"month\": month_f,\n",
    "        }\n",
    "\n",
    "        presto_model.eval()\n",
    "        encodings = presto_model.encoder(**input_d).detach().numpy()\n",
    "\n",
    "        encoding_list.append(encodings)\n",
    "        targets.append(y)\n",
    "\n",
    "    encodings_np = np.concatenate(encoding_list)\n",
    "    targets = np.concatenate(targets)\n",
    "\n",
    "    return encodings_np, targets\n",
    "\n",
    "\n",
    "def map_croptypes(\n",
    "    df: pd.DataFrame,\n",
    "    downstream_classes=\"CROPTYPE9\",\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    wc2ewoc_map = pd.read_csv(f\"{data_dir}/wc2eurocrops_map.csv\")\n",
    "    wc2ewoc_map[\"ewoc_code\"] = wc2ewoc_map[\"ewoc_code\"].str.replace(\"-\", \"\").astype(int)\n",
    "\n",
    "    ewoc_map = pd.read_csv(f\"{data_dir}/eurocrops_map_wcr_edition.csv\")\n",
    "    ewoc_map = ewoc_map[ewoc_map[\"ewoc_code\"].notna()]\n",
    "    ewoc_map[\"ewoc_code\"] = ewoc_map[\"ewoc_code\"].str.replace(\"-\", \"\").astype(int)\n",
    "    ewoc_map = ewoc_map.apply(lambda x: x[: x.last_valid_index()].ffill(), axis=1)\n",
    "    ewoc_map.set_index(\"ewoc_code\", inplace=True)\n",
    "\n",
    "    df[\"CROPTYPE_LABEL\"].replace(0, np.nan, inplace=True)\n",
    "    df[\"CROPTYPE_LABEL\"].fillna(df[\"LANDCOVER_LABEL\"], inplace=True)\n",
    "\n",
    "    df[\"ewoc_code\"] = df[\"CROPTYPE_LABEL\"].map(\n",
    "        wc2ewoc_map.set_index(\"croptype\")[\"ewoc_code\"]\n",
    "    )\n",
    "    df[\"landcover_name\"] = df[\"ewoc_code\"].map(ewoc_map[\"landcover_name\"])\n",
    "    df[\"cropgroup_name\"] = df[\"ewoc_code\"].map(ewoc_map[\"cropgroup_name\"])\n",
    "    df[\"croptype_name\"] = df[\"ewoc_code\"].map(ewoc_map[\"croptype_name\"])\n",
    "\n",
    "    df[\"downstream_class\"] = df[\"ewoc_code\"].map(\n",
    "        {int(k): v for k, v in CLASS_MAPPINGS[downstream_classes].items()}\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = duckdb.connect()\n",
    "db.sql('INSTALL spatial')\n",
    "db.load_extension(\"spatial\")\n",
    "\n",
    "parquet_path = \"s3://geoparquet/worldcereal_extractions_phase1/*/*.parquet\"\n",
    "\n",
    "# only querying the croptype data here\n",
    "public_df_raw = db.sql(\n",
    "    f\"\"\"\n",
    "set s3_endpoint='s3.waw3-1.cloudferro.com';\n",
    "select *\n",
    "from read_parquet('{parquet_path}', hive_partitioning = 1) original_data\n",
    "where st_within(ST_Point(original_data.lon, original_data.lat), ST_GeomFromText('{poly.wkt}'))\n",
    "and original_data.CROPTYPE_LABEL not in (0, 991, 7900, 9900, 9998, 1910, 1900, 1920, 1000, 11, 9910, 6212, 7920, 9520, 3400, 3900, 4390, 4000, 4300)\n",
    "\"\"\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75152, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = process_parquet(public_df_raw)\n",
    "public_df = map_croptypes(public_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Prepare own reference data\n",
    "\n",
    "Include some guidelines on how to upload user dataset to RDM (using the UI) and requesting those user samples through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = public_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Select desired crops for prediction\n",
    "\n",
    "Crops with ticked checkboxes will be included in the prediction. All the crops that are not selected will be grouped under the \"other_crop\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>croptype_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pasture_meadows</td>\n",
       "      <td>2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maize</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>potatoes</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permanent_crops</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     croptype_name  count\n",
       "0  pasture_meadows   2324\n",
       "1            maize   1861\n",
       "2         potatoes    208\n",
       "3  permanent_crops    183"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e88862d0f5414b95086974ac18ee07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='pasture_meadows (2324 samples)'), Checkbox(value=False, descâ€¦"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_threshold = 100\n",
    "potential_classes = merged_df['croptype_name'].value_counts().reset_index()\n",
    "potential_classes = potential_classes[potential_classes['count']>samples_threshold]\n",
    "\n",
    "checkbox_widgets = [widgets.Checkbox(value=False, description=f\"{row['croptype_name']} ({row['count']} samples)\") for ii,row in potential_classes.iterrows()]\n",
    "widgets.VBox(checkbox_widgets, layout=widgets.Layout(width='50%', display='inline-flex', flex_flow='row wrap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seleted_crops = [\n",
    "    checkbox.description.split(\" \")[0]\n",
    "    for checkbox in checkbox_widgets\n",
    "    if checkbox.value\n",
    "]\n",
    "merged_df[\"custom_class\"] = \"other\"\n",
    "merged_df.loc[\n",
    "    merged_df[\"croptype_name\"].isin(seleted_crops), \"custom_class\"\n",
    "] = merged_df[\"croptype_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_class\n",
       "pasture_meadows    2324\n",
       "maize              1861\n",
       "other               321\n",
       "potatoes            208\n",
       "permanent_crops     183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"custom_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extract required model inputs\n",
    "\n",
    "Here we launch point extractions for all samples intersecting our bbox resulting in a set of parquet files.\n",
    "\n",
    "We collect all these inputs and prepare presto features for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df, val_df = train_test_split(\n",
    "    merged_df,\n",
    "    stratify=merged_df[\"custom_class\"],\n",
    "    test_size=0.3,\n",
    "    random_state=DEFAULT_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "presto_model_path = f\"{data_dir}/presto-ss-wc-ft-ct-30D_test.pt\"\n",
    "presto_model = Presto.load_pretrained(model_path=presto_model_path, strict=False)\n",
    "\n",
    "train_encodings, train_targets = get_encodings_targets(trn_df, presto_model, batch_size=256)\n",
    "val_encodings, val_targets = get_encodings_targets(val_df, presto_model, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train custom classification model\n",
    "We train a catboost model and upload this model to artifactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6550097\ttest: 0.6250140\tbest: 0.6250140 (0)\ttotal: 160ms\tremaining: 21m 21s\n",
      "25:\tlearn: 0.6855338\ttest: 0.6656578\tbest: 0.6656578 (25)\ttotal: 2.78s\tremaining: 14m 14s\n",
      "50:\tlearn: 0.7196221\ttest: 0.6831521\tbest: 0.6831521 (50)\ttotal: 5.45s\tremaining: 14m 9s\n",
      "75:\tlearn: 0.7344926\ttest: 0.7032237\tbest: 0.7032237 (75)\ttotal: 8.13s\tremaining: 14m 8s\n",
      "100:\tlearn: 0.7496629\ttest: 0.7054853\tbest: 0.7054853 (100)\ttotal: 10.7s\tremaining: 13m 59s\n",
      "125:\tlearn: 0.7716846\ttest: 0.7173224\tbest: 0.7173224 (124)\ttotal: 13.4s\tremaining: 13m 59s\n",
      "150:\tlearn: 0.7924791\ttest: 0.7287346\tbest: 0.7293823 (145)\ttotal: 16.1s\tremaining: 13m 56s\n",
      "175:\tlearn: 0.8021751\ttest: 0.7394657\tbest: 0.7394662 (172)\ttotal: 18.8s\tremaining: 13m 56s\n",
      "200:\tlearn: 0.8170485\ttest: 0.7414905\tbest: 0.7414905 (196)\ttotal: 21.4s\tremaining: 13m 51s\n",
      "225:\tlearn: 0.8305947\ttest: 0.7475895\tbest: 0.7482350 (221)\ttotal: 24.1s\tremaining: 13m 48s\n",
      "250:\tlearn: 0.8409549\ttest: 0.7539567\tbest: 0.7539567 (250)\ttotal: 26.7s\tremaining: 13m 45s\n",
      "275:\tlearn: 0.8512454\ttest: 0.7542460\tbest: 0.7542460 (275)\ttotal: 29.6s\tremaining: 13m 47s\n",
      "300:\tlearn: 0.8586204\ttest: 0.7551175\tbest: 0.7568898 (287)\ttotal: 32.2s\tremaining: 13m 42s\n",
      "325:\tlearn: 0.8705353\ttest: 0.7587631\tbest: 0.7587631 (321)\ttotal: 34.9s\tremaining: 13m 41s\n",
      "350:\tlearn: 0.8809599\ttest: 0.7594228\tbest: 0.7595986 (344)\ttotal: 37.7s\tremaining: 13m 41s\n",
      "375:\tlearn: 0.8917668\ttest: 0.7629281\tbest: 0.7642275 (374)\ttotal: 40.3s\tremaining: 13m 37s\n",
      "400:\tlearn: 0.8958722\ttest: 0.7616331\tbest: 0.7642275 (374)\ttotal: 43s\tremaining: 13m 35s\n",
      "425:\tlearn: 0.9044305\ttest: 0.7656506\tbest: 0.7656506 (425)\ttotal: 45.7s\tremaining: 13m 31s\n",
      "450:\tlearn: 0.9136413\ttest: 0.7646362\tbest: 0.7656506 (425)\ttotal: 48.3s\tremaining: 13m 29s\n",
      "475:\tlearn: 0.9203089\ttest: 0.7646362\tbest: 0.7659379 (464)\ttotal: 51.1s\tremaining: 13m 27s\n",
      "500:\tlearn: 0.9265257\ttest: 0.7658206\tbest: 0.7664783 (491)\ttotal: 53.7s\tremaining: 13m 24s\n",
      "525:\tlearn: 0.9321693\ttest: 0.7639300\tbest: 0.7664783 (491)\ttotal: 56.3s\tremaining: 13m 20s\n",
      "550:\tlearn: 0.9362842\ttest: 0.7646150\tbest: 0.7665498 (534)\ttotal: 59s\tremaining: 13m 16s\n",
      "575:\tlearn: 0.9415383\ttest: 0.7687781\tbest: 0.7692676 (568)\ttotal: 1m 1s\tremaining: 13m 13s\n",
      "600:\tlearn: 0.9445765\ttest: 0.7709761\tbest: 0.7716399 (597)\ttotal: 1m 4s\tremaining: 13m 10s\n",
      "625:\tlearn: 0.9492060\ttest: 0.7724050\tbest: 0.7724323 (620)\ttotal: 1m 6s\tremaining: 13m 8s\n",
      "650:\tlearn: 0.9534334\ttest: 0.7739030\tbest: 0.7739030 (650)\ttotal: 1m 9s\tremaining: 13m 5s\n",
      "675:\tlearn: 0.9555489\ttest: 0.7730693\tbest: 0.7739030 (650)\ttotal: 1m 12s\tremaining: 13m 2s\n",
      "700:\tlearn: 0.9592891\ttest: 0.7724157\tbest: 0.7739030 (650)\ttotal: 1m 14s\tremaining: 13m\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.773902992\n",
      "bestIteration = 650\n",
      "\n",
      "Shrink model to first 651 iterations.\n"
     ]
    }
   ],
   "source": [
    "if np.unique(train_targets).shape[0] > 1:\n",
    "    eval_metric = \"TotalF1\"\n",
    "else:\n",
    "    eval_metric = \"F1\"\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(train_targets), y=train_targets)\n",
    "\n",
    "custom_downstream_model = CatBoostClassifier(\n",
    "    iterations=8000,\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    early_stopping_rounds=50,\n",
    "    # l2_leaf_reg=30,\n",
    "    colsample_bylevel=0.9,\n",
    "    l2_leaf_reg=6,\n",
    "    eval_metric=eval_metric,\n",
    "    random_state=DEFAULT_SEED,\n",
    "    # class_weights=class_weights,\n",
    "    verbose=25,\n",
    "    class_names=np.unique(train_targets),\n",
    ")\n",
    "\n",
    "custom_downstream_model.fit(\n",
    "    train_encodings, train_targets, eval_set=Pool(val_encodings, val_targets)\n",
    ")\n",
    "\n",
    "pred = custom_downstream_model.predict(val_encodings).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          maize       0.79      0.85      0.82       559\n",
      "          other       0.62      0.11      0.19        89\n",
      "pasture_meadows       0.81      0.91      0.85       698\n",
      "permanent_crops       0.79      0.27      0.41        55\n",
      "       potatoes       0.80      0.53      0.64        62\n",
      "\n",
      "       accuracy                           0.80      1463\n",
      "      macro avg       0.76      0.53      0.58      1463\n",
      "   weighted avg       0.79      0.80      0.77      1463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_targets, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generate a map\n",
    "\n",
    "Using our custom model, we generate a map for our region of interest..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
