{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./resources/System_v1_training_header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a demonstration on how to train custom crop type models based on your own reference data and how to apply the resulting model to generate a custom crop type map.\n",
    "\n",
    "# Content\n",
    "\n",
    "- [Before you start](#before-you-start)\n",
    "- [1. Define region of interest](#1.-Define-a-region-of-interest)\n",
    "- [2. Check public in-situ reference data](#2.-Check-public-in-situ-reference-data)\n",
    "- [3. Prepare own reference data](#3.-Prepare-own-reference-data)\n",
    "- [4. Extract required model inputs](#4.-Extract-required-model-inputs)\n",
    "- [5. Train custom classification model](#5.-Train-custom-classification-model)\n",
    "- [6. Generate a map](#6.-Generate-a-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "In order to run this notebook, you need to create an account on:\n",
    "\n",
    "- The Copernicus Data Space Ecosystem (CDSE)\n",
    "--> by completing the form [HERE](https://identity.dataspace.copernicus.eu/auth/realms/CDSE/login-actions/registration?client_id=cdse-public&tab_id=eRKGqDvoYI0)\n",
    "\n",
    "- VITO's Terrascope platform\n",
    "--> by completing the form [HERE](https://sso.terrascope.be/auth/realms/terrascope/login-actions/registration?client_id=drupal-terrascope&tab_id=irBzckp2aDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import get_ui_map\n",
    "RDM_API = \"https://ewoc-rdm-api.iiasa.ac.at\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define a region of interest\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest.\n",
    "When finished, execute the second cell to store the coordinates of your region of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fa1b36314f40a3bb167c92959d74b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[51.1872, 5.1154], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoo…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, dc = get_ui_map()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your area of interest: (2.05719, 48.114767, 2.121735, 48.154177)\n",
      "Area of processing extent: 21.54 km²\n"
     ]
    }
   ],
   "source": [
    "# retrieve bounding box from drawn rectangle\n",
    "from worldcereal.utils.map import get_bbox_from_draw\n",
    "\n",
    "spatial_extent, bbox, poly = get_bbox_from_draw(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract public in situ reference data\n",
    "\n",
    "Here we query existing reference data that have already been processed by WorldCereal and are ready to use.\n",
    "We filter for croptype labels by default, intersecting with a buffer around the bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying a buffer of 250.0 km to the selected area ...\n",
      "Querying WorldCereal global database ...\n",
      "Processing selected samples ...\n",
      "Extracted and processed 6110 samples from global database.\n"
     ]
    }
   ],
   "source": [
    "from utils import query_worldcereal_samples\n",
    "\n",
    "public_df = query_worldcereal_samples(poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select desired crops for prediction\n",
    "\n",
    "Crops with ticked checkboxes will be included in the prediction. All the crops that are not selected will be grouped under the \"other_crop\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b5bd3236f94989b315d9ad9382370e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='unspecified_wheat (2610 samples)'), Checkbox(value=False, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import pick_croptypes\n",
    "from IPython.display import display\n",
    "\n",
    "checkbox, checkbox_widgets = pick_croptypes(public_df, samples_threshold=100)\n",
    "display(checkbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_class\n",
       "other            4638\n",
       "rapeseed_rape     700\n",
       "maize             592\n",
       "sunflower         180\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_custom_labels\n",
    "\n",
    "public_df = get_custom_labels(public_df, checkbox_widgets)\n",
    "public_df['custom_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extract required model inputs\n",
    "\n",
    "Here we prepare presto features for each sample by using a model pretrained on WorldCereal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Presto model ...\n",
      "Computing Presto embeddings ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from utils import get_inputs_outputs\n",
    "\n",
    "encodings, targets = get_inputs_outputs(public_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train custom classification model\n",
    "We train a catboost model for the selected crop types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split train/test ...\n",
      "Computing class weights ...\n",
      "Class weights: {'maize': 2.582729468599034, 'other': 0.32930397289805974, 'rapeseed_rape': 2.182142857142857, 'sunflower': 8.48611111111111}\n",
      "Training CatBoost classifier ...\n",
      "0:\tlearn: 1.3259160\ttest: 1.3342568\tbest: 1.3342568 (0)\ttotal: 123ms\tremaining: 16m 20s\n",
      "25:\tlearn: 0.6451892\ttest: 0.7801960\tbest: 0.7801960 (25)\ttotal: 1.79s\tremaining: 9m 7s\n",
      "50:\tlearn: 0.4330030\ttest: 0.6280405\tbest: 0.6280405 (50)\ttotal: 3.45s\tremaining: 8m 58s\n",
      "75:\tlearn: 0.3249919\ttest: 0.5593450\tbest: 0.5593450 (75)\ttotal: 4.69s\tremaining: 8m 9s\n",
      "100:\tlearn: 0.2617507\ttest: 0.5265702\tbest: 0.5265702 (100)\ttotal: 5.89s\tremaining: 7m 40s\n",
      "125:\tlearn: 0.2194401\ttest: 0.5108148\tbest: 0.5108148 (125)\ttotal: 7.13s\tremaining: 7m 25s\n",
      "150:\tlearn: 0.1925367\ttest: 0.5042110\tbest: 0.5042110 (150)\ttotal: 8.37s\tremaining: 7m 15s\n",
      "175:\tlearn: 0.1700891\ttest: 0.5011448\tbest: 0.5009937 (174)\ttotal: 9.56s\tremaining: 7m 5s\n",
      "200:\tlearn: 0.1544099\ttest: 0.5005817\tbest: 0.4995323 (188)\ttotal: 10.7s\tremaining: 6m 54s\n",
      "225:\tlearn: 0.1401264\ttest: 0.4991938\tbest: 0.4985037 (216)\ttotal: 11.7s\tremaining: 6m 42s\n",
      "250:\tlearn: 0.1296249\ttest: 0.4998449\tbest: 0.4985037 (216)\ttotal: 12.9s\tremaining: 6m 39s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.4985036524\n",
      "bestIteration = 216\n",
      "\n",
      "Shrink model to first 217 iterations.\n"
     ]
    }
   ],
   "source": [
    "from utils import train_classifier\n",
    "\n",
    "custom_model, report = train_classifier(encodings, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        maize       0.68      0.87      0.76       178\n",
      "        other       0.97      0.89      0.93      1391\n",
      "rapeseed_rape       0.75      0.91      0.83       210\n",
      "    sunflower       0.46      0.61      0.52        54\n",
      "\n",
      "     accuracy                           0.88      1833\n",
      "    macro avg       0.71      0.82      0.76      1833\n",
      " weighted avg       0.90      0.88      0.89      1833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Deploy custom model\n",
    "\n",
    "Once trained, we have to upload our model to the cloud so it can be used for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading model to `demo_20240702155132_custommodel.onnx`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed to: https://artifactory.vgt.vito.be/artifactory/worldcereal_models/demo_20240702155132_custommodel.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100 6228k    0   793  100 6227k   1025  8056k --:--:-- --:--:-- --:--:-- 8057k\n"
     ]
    }
   ],
   "source": [
    "from utils import deploy_model\n",
    "\n",
    "model_url = deploy_model(custom_model, pattern='demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generate a map\n",
    "\n",
    "Using our custom model, we generate a map for our region of interest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n",
      "Selected orbit direction: DESCENDING from max accumulated area overlap between bounds and products.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:PrestoFeatureExtractor:No additional dependencies are defined. If you wish to add dependencies to your feature extractor, override the `dependencies` method in your class.\n",
      "WARNING:PrestoFeatureExtractor:No additional dependencies are defined. If you wish to add dependencies to your feature extractor, override the `dependencies` method in your class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-240702e26f9443d4aa8ac210d87fc865': send 'start'\n"
     ]
    }
   ],
   "source": [
    "from worldcereal.job import WorldCerealProduct, generate_map, CropTypeParameters    \n",
    "from openeo_gfmap import TemporalContext\n",
    "\n",
    "# Set temporal range to generate product\n",
    "temporal_extent = TemporalContext(\n",
    "    start_date=\"2021-11-01\",\n",
    "    end_date=\"2022-10-31\",\n",
    ")\n",
    "\n",
    "# Initializes default parameters \n",
    "parameters = CropTypeParameters()\n",
    "\n",
    "# Change the URL to the classification model\n",
    "parameters.classifier_parameters.classifier_url = model_url\n",
    "\n",
    "# Launch the job\n",
    "job_results = generate_map(\n",
    "    spatial_extent,\n",
    "    temporal_extent,\n",
    "    output_path='./cropmap.tif',\n",
    "    product_type=WorldCerealProduct.CROPTYPE,\n",
    "    croptype_parameters=parameters,\n",
    "    out_format=\"GTiff\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
