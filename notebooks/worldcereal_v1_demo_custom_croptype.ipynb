{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./resources/System_v1_training_header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Before you start](#toc1_)    \n",
    "- [Define a region of interest](#toc2_)    \n",
    "- [Extract public in situ reference data](#toc3_)    \n",
    "- [Select desired crops for prediction](#toc4_)    \n",
    "- [Extract required model inputs](#toc5_)    \n",
    "- [Train custom classification model](#toc6_)    \n",
    "- [Deploy custom model](#toc7_)    \n",
    "- [Generate a map](#toc8_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Before you start](#toc0_)\n",
    "\n",
    "In order to run WorldCereal crop mapping jobs from this notebook, you need to create an account on the Copernicus Data Space Ecosystem (CDSE) registering [here](https://dataspace.copernicus.eu/). This is free of charge and will grant you a number of free openEO processing credits to continue this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Define a region and time of interest](#toc0_)\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest. Currently, there is a maximum size of 250 km² for your area within this demo, shown during drawing of the polygon.\n",
    "\n",
    "When finished, execute the second cell to store the coordinates of your region of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5aa17dbf084ece8b2df3c44256fa33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[51.1872, 5.1154], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoo…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from worldcereal.utils.map import get_ui_map\n",
    "\n",
    "m, dc = get_ui_map()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-01 20:46:08.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworldcereal.utils.map\u001b[0m:\u001b[36mget_bbox_from_draw\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mYour area of interest: (4.826202, 51.068729, 4.91272, 51.108408)\u001b[0m\n",
      "\u001b[32m2024-10-01 20:46:08.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworldcereal.utils.map\u001b[0m:\u001b[36mget_bbox_from_draw\u001b[0m:\u001b[36m470\u001b[0m - \u001b[1mArea of processing extent: 28.18 km²\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# retrieve bounding box from drawn rectangle\n",
    "from worldcereal.utils.map import get_bbox_from_draw\n",
    "\n",
    "spatial_extent, bbox, poly = get_bbox_from_draw(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Extract public extractions](#toc0_)\n",
    "\n",
    "Here we query existing reference data that have already been processed by WorldCereal and are ready to use.\n",
    "We filter for croptype labels by default, intersecting with a buffer (250 km by default) around the bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-01 20:46:12.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworldcereal.utils.refdata\u001b[0m:\u001b[36mquery_public_extractions\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mApplying a buffer of 250.0 km to the selected area ...\u001b[0m\n",
      "\u001b[32m2024-10-01 20:46:12.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworldcereal.utils.refdata\u001b[0m:\u001b[36mquery_public_extractions\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mQuerying WorldCereal global extractions database (this can take a while) ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-01 20:49:08.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworldcereal.utils.refdata\u001b[0m:\u001b[36mprocess_parquet\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mProcessing selected samples ...\u001b[0m\n",
      "\u001b[32m2024-10-01 20:49:10.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworldcereal.utils.refdata\u001b[0m:\u001b[36mprocess_parquet\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mExtracted and processed 39126 samples from global database.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from worldcereal.utils.refdata import query_public_extractions\n",
    "\n",
    "public_df = query_public_extractions(poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Select desired crops for prediction](#toc0_)\n",
    "\n",
    "Crops with ticked checkboxes will be included in the prediction. All the crops that are not selected will be grouped under the \"other_crop\" category. The model will be trained in a multi-class setting, not a hierarchical one. Keep this in mind when choosing your crop types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f25d02e7ecc453c9fb1442f4dd3aa5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='maize (20379 samples)'), Checkbox(value=False, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import pick_croptypes\n",
    "from IPython.display import display\n",
    "\n",
    "checkbox, checkbox_widgets = pick_croptypes(public_df, samples_threshold=100)\n",
    "display(checkbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your selection, a custom target label is now generated for each sample. Verify that only crops of your choice are appearing in the `custom_class`, all others will fall under `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downstream_class\n",
       "maize                 20474\n",
       "unspecified_wheat      5876\n",
       "potatoes               4948\n",
       "other                  4380\n",
       "beet                   1963\n",
       "unspecified_barley     1746\n",
       "rapeseed_rape           529\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_custom_labels\n",
    "\n",
    "public_df = get_custom_labels(public_df, checkbox_widgets)\n",
    "public_df[\"downstream_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Extract required model inputs](#toc0_)\n",
    "\n",
    "Here we prepare presto inputs features for each sample by using a model pretrained on WorldCereal data. The resulting `encodings` and `targets` will be used for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-01 10:13:32.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mget_inputs_outputs\u001b[0m:\u001b[36m79\u001b[0m - \u001b[1mPresto URL: https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/presto-ss-wc-ft-ct_long-parquet_30D_CROPTYPE0_split%3Drandom_time-token%3Dmonth_balance%3DTrue_augment%3DTrue.pt\u001b[0m\n",
      "\u001b[32m2024-10-01 10:13:33.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mget_inputs_outputs\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mComputing Presto embeddings ...\u001b[0m\n",
      "\u001b[32m2024-10-01 10:14:48.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mget_inputs_outputs\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mDone.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from utils import get_inputs_outputs\n",
    "\n",
    "encodings, targets = get_inputs_outputs(public_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Train custom classification model](#toc0_)\n",
    "We train a catboost model for the selected crop types. Class weights are automatically determined to balance the individual classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-01 10:15:12.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mtrain_classifier\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mSplit train/test ...\u001b[0m\n",
      "\u001b[32m2024-10-01 10:15:12.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mtrain_classifier\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mComputing class weights ...\u001b[0m\n",
      "\u001b[32m2024-10-01 10:15:12.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mtrain_classifier\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mClass weights:\u001b[0m\n",
      "\u001b[32m2024-10-01 10:15:12.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mtrain_classifier\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mTraining CatBoost classifier ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.052152\n",
      "0:\tlearn: 1.6755078\ttest: 1.6794653\tbest: 1.6794653 (0)\ttotal: 168ms\tremaining: 22m 23s\n",
      "25:\tlearn: 0.7611667\ttest: 0.8103459\tbest: 0.8103459 (25)\ttotal: 3.15s\tremaining: 16m 6s\n",
      "50:\tlearn: 0.5645676\ttest: 0.6439129\tbest: 0.6439129 (50)\ttotal: 5.99s\tremaining: 15m 34s\n",
      "75:\tlearn: 0.4814657\ttest: 0.5844641\tbest: 0.5844641 (75)\ttotal: 8.74s\tremaining: 15m 11s\n",
      "100:\tlearn: 0.4324872\ttest: 0.5553868\tbest: 0.5553868 (100)\ttotal: 11.5s\tremaining: 14m 56s\n",
      "125:\tlearn: 0.3987216\ttest: 0.5393044\tbest: 0.5393044 (125)\ttotal: 14.3s\tremaining: 14m 52s\n",
      "150:\tlearn: 0.3722066\ttest: 0.5301795\tbest: 0.5301795 (150)\ttotal: 17.3s\tremaining: 14m 58s\n",
      "175:\tlearn: 0.3509112\ttest: 0.5247165\tbest: 0.5247165 (175)\ttotal: 20.1s\tremaining: 14m 54s\n",
      "200:\tlearn: 0.3335955\ttest: 0.5202964\tbest: 0.5202964 (200)\ttotal: 22.9s\tremaining: 14m 47s\n",
      "225:\tlearn: 0.3209134\ttest: 0.5177398\tbest: 0.5177398 (225)\ttotal: 25.5s\tremaining: 14m 37s\n",
      "250:\tlearn: 0.3088239\ttest: 0.5154368\tbest: 0.5154368 (250)\ttotal: 28.3s\tremaining: 14m 33s\n",
      "275:\tlearn: 0.2971624\ttest: 0.5140281\tbest: 0.5140281 (275)\ttotal: 31.2s\tremaining: 14m 32s\n",
      "300:\tlearn: 0.2877981\ttest: 0.5129740\tbest: 0.5129740 (300)\ttotal: 33.9s\tremaining: 14m 26s\n",
      "325:\tlearn: 0.2788151\ttest: 0.5125131\tbest: 0.5123765 (324)\ttotal: 36.6s\tremaining: 14m 21s\n",
      "350:\tlearn: 0.2698962\ttest: 0.5119255\tbest: 0.5118170 (336)\ttotal: 39.5s\tremaining: 14m 21s\n",
      "375:\tlearn: 0.2619724\ttest: 0.5112224\tbest: 0.5112224 (375)\ttotal: 42.2s\tremaining: 14m 15s\n",
      "400:\tlearn: 0.2542943\ttest: 0.5103876\tbest: 0.5103733 (399)\ttotal: 44.9s\tremaining: 14m 10s\n",
      "425:\tlearn: 0.2478864\ttest: 0.5099352\tbest: 0.5099352 (425)\ttotal: 47.5s\tremaining: 14m 4s\n",
      "450:\tlearn: 0.2411571\ttest: 0.5099200\tbest: 0.5098527 (427)\ttotal: 50.4s\tremaining: 14m 3s\n",
      "475:\tlearn: 0.2349075\ttest: 0.5098079\tbest: 0.5098079 (475)\ttotal: 53.2s\tremaining: 14m\n",
      "500:\tlearn: 0.2294402\ttest: 0.5097363\tbest: 0.5094968 (491)\ttotal: 56s\tremaining: 13m 58s\n",
      "525:\tlearn: 0.2237800\ttest: 0.5098131\tbest: 0.5094968 (491)\ttotal: 58.7s\tremaining: 13m 54s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.5094967705\n",
      "bestIteration = 491\n",
      "\n",
      "Shrink model to first 492 iterations.\n"
     ]
    }
   ],
   "source": [
    "from utils import train_classifier\n",
    "\n",
    "custom_model, report, confusion_matrix = train_classifier(encodings, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             maize       0.94      0.89      0.92      6142\n",
      "             other       0.71      0.76      0.74      1903\n",
      "          potatoes       0.77      0.81      0.79      1484\n",
      "     rapeseed_rape       0.83      0.89      0.86       159\n",
      "unspecified_barley       0.65      0.77      0.71       524\n",
      " unspecified_wheat       0.85      0.87      0.86      1763\n",
      "\n",
      "          accuracy                           0.85     11975\n",
      "         macro avg       0.79      0.83      0.81     11975\n",
      "      weighted avg       0.86      0.85      0.85     11975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[Deploy custom model](#toc0_)\n",
    "\n",
    "Once trained, we have to upload our model to the cloud so it can be used for inference. Note that these models are only kept in cloud storage for a limited amount of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-01 10:16:27.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mdeploy_model\u001b[0m:\u001b[36m257\u001b[0m - \u001b[1mUploading model to `demo_newpresto_20241001101627_custommodel.onnx`\u001b[0m\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 17.0M    0   824  100 17.0M   1612  33.4M --:--:-- --:--:-- --:--:-- 33.4M\n",
      "\u001b[32m2024-10-01 10:18:39.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mdeploy_model\u001b[0m:\u001b[36m273\u001b[0m - \u001b[1mDeployed to: https://artifactory.vgt.vito.be/artifactory/worldcereal_models/demo_newpresto_20241001101627_custommodel.onnx\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from worldcereal.utils.upload import deploy_model\n",
    "from openeo_gfmap.backend import cdse_connection\n",
    "\n",
    "model_url = deploy_model(cdse_connection(), custom_model, pattern=\"demo_newpresto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[Generate a map](#toc0_)\n",
    "\n",
    "Using our custom model, we generate a map for our region of interest and download the result.\n",
    "\n",
    "You can also manually download the resulting GeoTIFF by clicking on the link that will be diplayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openeo.rest.connection:Found OIDC providers: ['CDSE']\n",
      "INFO:openeo.rest.connection:No OIDC provider given, but only one available: 'CDSE'. Using that one.\n",
      "INFO:openeo.rest.connection:Using default client_id 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e' from OIDC provider 'CDSE' info.\n",
      "INFO:openeo.rest.connection:Found refresh token: trying refresh token based authentication.\n",
      "INFO:openeo.rest.auth.oidc:Doing 'refresh_token' token request 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' with post data fields ['grant_type', 'client_id', 'refresh_token'] (client_id 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e')\n",
      "INFO:openeo.rest.connection:Obtained tokens: ['access_token', 'id_token', 'refresh_token']\n",
      "INFO:openeo.rest.auth.config:Storing refresh token for issuer 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE' (client 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 11:52:24,363 - openeo_gfmap.utils - INFO - Selected orbit state: DESCENDING. Reason: Orbit has more cumulative intersected area. 8.633429223099554 > 8.407504384493565\n",
      "INFO:openeo_gfmap.utils:Selected orbit state: DESCENDING. Reason: Orbit has more cumulative intersected area. 8.633429223099554 > 8.407504384493565\n",
      "WARNING:PrestoFeatureExtractor:No additional dependencies are defined. If you wish to add dependencies to your feature extractor, override the `dependencies` method in your class.\n",
      "WARNING:PrestoFeatureExtractor:No additional dependencies are defined. If you wish to add dependencies to your feature extractor, override the `dependencies` method in your class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-241001332d7d4e61a08974174878fbbc': send 'start'\n",
      "0:00:39 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:00:54 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:01:01 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:01:09 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:01:19 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:01:33 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:01:49 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:02:08 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:02:32 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:03:09 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:03:57 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:04:43 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:05:52 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:06:52 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:07:52 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:08:55 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:09:55 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:10:55 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:11:56 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:12:57 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:13:57 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:15:01 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:16:01 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:17:01 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:18:12 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:19:22 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:20:23 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:21:23 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:22:23 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:23:24 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:24:24 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:25:24 Job 'j-241001332d7d4e61a08974174878fbbc': running (progress N/A)\n",
      "0:26:25 Job 'j-241001332d7d4e61a08974174878fbbc': finished (progress 100%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openeo.rest.job:Downloading Job result asset 'openEO_2020-01-01Z.tif' from https://openeo.creo.vito.be/openeo/jobs/j-241001332d7d4e61a08974174878fbbc/results/assets/NGZkOWRiOTYtZDYyMC00NDU0LTliZTYtMTRhN2Q4ZTkyMzU3/0d7faef7f7b036c6c86a9740cc542ee9/openEO_2020-01-01Z.tif?expires=1728382748 to cropmap_newpresto.tif\n"
     ]
    }
   ],
   "source": [
    "from worldcereal.job import WorldCerealProductType, generate_map, CropTypeParameters, PostprocessParameters\n",
    "from openeo_gfmap import TemporalContext\n",
    "\n",
    "# Set temporal range to generate product\n",
    "temporal_extent = TemporalContext(\n",
    "    start_date=\"2020-12-01\",\n",
    "    end_date=\"2021-11-30\",\n",
    ")\n",
    "\n",
    "# Initializes default parameters\n",
    "parameters = CropTypeParameters()\n",
    "\n",
    "# Change the URL to the classification model\n",
    "parameters.classifier_parameters.classifier_url = model_url\n",
    "\n",
    "# Launch the job\n",
    "job_results = generate_map(\n",
    "    spatial_extent,\n",
    "    temporal_extent,\n",
    "    output_path=\"./cropmap_newpresto.tif\",\n",
    "    product_type=WorldCerealProductType.CROPTYPE,\n",
    "    croptype_parameters=parameters,\n",
    "    postprocess_parameters=PostprocessParameters(enable=True),\n",
    "    job_options={\"python-memory\": \"4g\"},\n",
    "    out_format=\"GTiff\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For interpreting your raster, the following information is useful:\n",
    "- Band 1 contains the class integers and by executing the cell below you can check which integer belongs to which crop type\n",
    "- Band 2 contains the probability associated to the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster value - Class name\n",
      "0 -> maize\n",
      "1 -> other\n",
      "2 -> potatoes\n",
      "3 -> rapeseed_rape\n",
      "4 -> unspecified_barley\n",
      "5 -> unspecified_wheat\n"
     ]
    }
   ],
   "source": [
    "LUT = {class_int: class_name for class_int, class_name in enumerate(custom_model.get_params()['class_names'])}\n",
    "print('Raster value - Class name')\n",
    "for key, value in LUT.items():\n",
    "    print(f\"{key} -> {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
