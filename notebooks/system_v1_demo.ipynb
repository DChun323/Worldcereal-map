{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./resources/System_v1_training_header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Before you start](#toc1_)    \n",
    "- [Define a region of interest](#toc2_)    \n",
    "- [Extract public in situ reference data](#toc3_)    \n",
    "- [Select desired crops for prediction](#toc4_)    \n",
    "- [Extract required model inputs](#toc5_)    \n",
    "- [Train custom classification model](#toc6_)    \n",
    "- [Deploy custom model](#toc7_)    \n",
    "- [Generate a map](#toc8_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Before you start](#toc0_)\n",
    "\n",
    "In order to run this notebook, you need to create an account on the Copernicus Data Space Ecosystem (CDSE) by completing [this](https://identity.dataspace.copernicus.eu/auth/realms/CDSE/login-actions/registration?client_id=cdse-public&tab_id=eRKGqDvoYI0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Define a region of interest](#toc0_)\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest. Currently, there is a maximum size of 100 km² for your area, shown during drawing of the polygon.\n",
    "\n",
    "When finished, execute the second cell to store the coordinates of your region of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9dda40c7fa40db899dc62e4dd9160c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[51.1872, 5.1154], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoo…"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from worldcereal.utils.map import get_ui_map\n",
    "\n",
    "m, dc = get_ui_map()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your area of interest: (4.930115, 50.61636, 5.015259, 50.661649)\n",
      "Area of processing extent: 31.98 km²\n"
     ]
    }
   ],
   "source": [
    "# retrieve bounding box from drawn rectangle\n",
    "from worldcereal.utils.map import get_bbox_from_draw\n",
    "\n",
    "spatial_extent, bbox, poly = get_bbox_from_draw(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Extract public in situ reference data](#toc0_)\n",
    "\n",
    "Here we query existing reference data that have already been processed by WorldCereal and are ready to use.\n",
    "We filter for croptype labels by default, intersecting with a buffer (250 km by default) around the bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying a buffer of 250.0 km to the selected area ...\n",
      "Querying WorldCereal global database ...\n",
      "Processing selected samples ...\n",
      "Extracted and processed 39192 samples from global database.\n"
     ]
    }
   ],
   "source": [
    "from utils import query_worldcereal_samples\n",
    "\n",
    "public_df = query_worldcereal_samples(poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Select desired crops for prediction](#toc0_)\n",
    "\n",
    "Crops with ticked checkboxes will be included in the prediction. All the crops that are not selected will be grouped under the \"other_crop\" category. The model will be trained in a multi-class setting, not a hierarchical one. Keep this in mind when choosing your crop types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e24cc51c13a48e39c46445385711b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='maize (20276 samples)'), Checkbox(value=False, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import pick_croptypes\n",
    "from IPython.display import display\n",
    "\n",
    "checkbox, checkbox_widgets = pick_croptypes(public_df, samples_threshold=100)\n",
    "display(checkbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your selection, a custom target label is now generated for each sample. Verify that only crops of your choice are appearing in the `custom_class`, all others will fall under `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_class\n",
       "maize                 20276\n",
       "unspecified_wheat      5664\n",
       "potatoes               4830\n",
       "other                  4813\n",
       "beet                   1908\n",
       "unspecified_barley     1701\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_custom_labels\n",
    "\n",
    "public_df = get_custom_labels(public_df, checkbox_widgets)\n",
    "public_df[\"custom_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Extract required model inputs](#toc0_)\n",
    "\n",
    "Here we prepare presto inputs features for each sample by using a model pretrained on WorldCereal data. The resulting `encodings` and `targets` will be used for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Presto embeddings ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from utils import get_inputs_outputs\n",
    "\n",
    "encodings, targets = get_inputs_outputs(public_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Train custom classification model](#toc0_)\n",
    "We train a catboost model for the selected crop types. Class weights are automatically determined to balance the individual classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split train/test ...\n",
      "Computing class weights ...\n",
      "Class weights: {'beet': 3.424968789013733, 'maize': 0.32215411353014395, 'other': 1.3571781933313545, 'potatoes': 1.352361234348812, 'unspecified_barley': 3.8390708088441086, 'unspecified_wheat': 1.1531736023539303}\n",
      "Training CatBoost classifier ...\n",
      "0:\tlearn: 1.7407270\ttest: 1.7437118\tbest: 1.7437118 (0)\ttotal: 101ms\tremaining: 13m 24s\n",
      "25:\tlearn: 1.1963429\ttest: 1.2453393\tbest: 1.2453393 (25)\ttotal: 2.57s\tremaining: 13m 7s\n",
      "50:\tlearn: 1.0100359\ttest: 1.0921785\tbest: 1.0921785 (50)\ttotal: 5.03s\tremaining: 13m 3s\n",
      "75:\tlearn: 0.9027329\ttest: 1.0121642\tbest: 1.0121642 (75)\ttotal: 7.59s\tremaining: 13m 11s\n",
      "100:\tlearn: 0.8274552\ttest: 0.9621098\tbest: 0.9621098 (100)\ttotal: 10s\tremaining: 13m 4s\n",
      "125:\tlearn: 0.7687655\ttest: 0.9278064\tbest: 0.9278064 (125)\ttotal: 12.3s\tremaining: 12m 48s\n",
      "150:\tlearn: 0.7207899\ttest: 0.9012466\tbest: 0.9012466 (150)\ttotal: 14.7s\tremaining: 12m 45s\n",
      "175:\tlearn: 0.6801320\ttest: 0.8809879\tbest: 0.8809879 (175)\ttotal: 17.2s\tremaining: 12m 43s\n",
      "200:\tlearn: 0.6459756\ttest: 0.8640860\tbest: 0.8640860 (200)\ttotal: 19.6s\tremaining: 12m 39s\n",
      "225:\tlearn: 0.6164809\ttest: 0.8505857\tbest: 0.8505857 (225)\ttotal: 21.9s\tremaining: 12m 33s\n",
      "250:\tlearn: 0.5910335\ttest: 0.8395279\tbest: 0.8395279 (250)\ttotal: 24.2s\tremaining: 12m 25s\n",
      "275:\tlearn: 0.5667883\ttest: 0.8304940\tbest: 0.8304940 (275)\ttotal: 26.6s\tremaining: 12m 24s\n",
      "300:\tlearn: 0.5427643\ttest: 0.8219318\tbest: 0.8219318 (300)\ttotal: 29s\tremaining: 12m 21s\n",
      "325:\tlearn: 0.5225822\ttest: 0.8146088\tbest: 0.8146088 (325)\ttotal: 31.3s\tremaining: 12m 15s\n",
      "350:\tlearn: 0.5051648\ttest: 0.8088678\tbest: 0.8088678 (350)\ttotal: 33.6s\tremaining: 12m 11s\n",
      "375:\tlearn: 0.4884131\ttest: 0.8028413\tbest: 0.8028413 (375)\ttotal: 35.8s\tremaining: 12m 6s\n",
      "400:\tlearn: 0.4719619\ttest: 0.7981579\tbest: 0.7981579 (400)\ttotal: 38.1s\tremaining: 12m 2s\n",
      "425:\tlearn: 0.4572550\ttest: 0.7937336\tbest: 0.7937336 (425)\ttotal: 40.4s\tremaining: 11m 58s\n",
      "450:\tlearn: 0.4441412\ttest: 0.7901283\tbest: 0.7901283 (450)\ttotal: 42.8s\tremaining: 11m 55s\n",
      "475:\tlearn: 0.4309527\ttest: 0.7872280\tbest: 0.7872280 (475)\ttotal: 45.1s\tremaining: 11m 52s\n",
      "500:\tlearn: 0.4187095\ttest: 0.7843079\tbest: 0.7843079 (500)\ttotal: 47.5s\tremaining: 11m 51s\n",
      "525:\tlearn: 0.4067694\ttest: 0.7814679\tbest: 0.7814679 (525)\ttotal: 49.8s\tremaining: 11m 47s\n",
      "550:\tlearn: 0.3950706\ttest: 0.7795853\tbest: 0.7795853 (550)\ttotal: 52.1s\tremaining: 11m 44s\n",
      "575:\tlearn: 0.3851674\ttest: 0.7774665\tbest: 0.7774665 (575)\ttotal: 54.5s\tremaining: 11m 43s\n",
      "600:\tlearn: 0.3753192\ttest: 0.7756031\tbest: 0.7756031 (600)\ttotal: 56.8s\tremaining: 11m 39s\n",
      "625:\tlearn: 0.3662575\ttest: 0.7736807\tbest: 0.7736807 (625)\ttotal: 59.1s\tremaining: 11m 35s\n",
      "650:\tlearn: 0.3568165\ttest: 0.7716535\tbest: 0.7716535 (650)\ttotal: 1m 1s\tremaining: 11m 33s\n",
      "675:\tlearn: 0.3472091\ttest: 0.7696927\tbest: 0.7696927 (675)\ttotal: 1m 3s\tremaining: 11m 30s\n",
      "700:\tlearn: 0.3388759\ttest: 0.7679028\tbest: 0.7679028 (700)\ttotal: 1m 6s\tremaining: 11m 31s\n",
      "725:\tlearn: 0.3306194\ttest: 0.7669178\tbest: 0.7669178 (725)\ttotal: 1m 9s\tremaining: 11m 39s\n",
      "750:\tlearn: 0.3227659\ttest: 0.7661688\tbest: 0.7661493 (749)\ttotal: 1m 12s\tremaining: 11m 41s\n",
      "775:\tlearn: 0.3156707\ttest: 0.7650619\tbest: 0.7650619 (775)\ttotal: 1m 15s\tremaining: 11m 40s\n",
      "800:\tlearn: 0.3083661\ttest: 0.7640502\tbest: 0.7640430 (798)\ttotal: 1m 17s\tremaining: 11m 38s\n",
      "825:\tlearn: 0.3013556\ttest: 0.7630508\tbest: 0.7630508 (825)\ttotal: 1m 20s\tremaining: 11m 37s\n",
      "850:\tlearn: 0.2945372\ttest: 0.7625637\tbest: 0.7625280 (847)\ttotal: 1m 22s\tremaining: 11m 34s\n",
      "875:\tlearn: 0.2885137\ttest: 0.7614814\tbest: 0.7614814 (875)\ttotal: 1m 24s\tremaining: 11m 31s\n",
      "900:\tlearn: 0.2825680\ttest: 0.7607729\tbest: 0.7606986 (899)\ttotal: 1m 27s\tremaining: 11m 28s\n",
      "925:\tlearn: 0.2768142\ttest: 0.7598923\tbest: 0.7598239 (921)\ttotal: 1m 29s\tremaining: 11m 26s\n",
      "950:\tlearn: 0.2715782\ttest: 0.7591296\tbest: 0.7591296 (950)\ttotal: 1m 32s\tremaining: 11m 24s\n",
      "975:\tlearn: 0.2660035\ttest: 0.7590100\tbest: 0.7589259 (973)\ttotal: 1m 35s\tremaining: 11m 28s\n",
      "1000:\tlearn: 0.2606031\ttest: 0.7585913\tbest: 0.7584772 (998)\ttotal: 1m 39s\tremaining: 11m 38s\n",
      "1025:\tlearn: 0.2561310\ttest: 0.7583439\tbest: 0.7582827 (1024)\ttotal: 1m 44s\tremaining: 11m 48s\n",
      "1050:\tlearn: 0.2510235\ttest: 0.7581075\tbest: 0.7580597 (1046)\ttotal: 1m 47s\tremaining: 11m 51s\n",
      "1075:\tlearn: 0.2459794\ttest: 0.7581203\tbest: 0.7580310 (1068)\ttotal: 1m 51s\tremaining: 11m 54s\n",
      "1100:\tlearn: 0.2415720\ttest: 0.7578295\tbest: 0.7578130 (1097)\ttotal: 1m 53s\tremaining: 11m 54s\n",
      "1125:\tlearn: 0.2372298\ttest: 0.7576193\tbest: 0.7574650 (1121)\ttotal: 1m 56s\tremaining: 11m 53s\n",
      "1150:\tlearn: 0.2327887\ttest: 0.7575252\tbest: 0.7573356 (1135)\ttotal: 2m\tremaining: 11m 56s\n",
      "1175:\tlearn: 0.2284499\ttest: 0.7572249\tbest: 0.7572031 (1170)\ttotal: 2m 4s\tremaining: 12m 1s\n",
      "1200:\tlearn: 0.2246747\ttest: 0.7570067\tbest: 0.7569755 (1199)\ttotal: 2m 7s\tremaining: 12m 4s\n",
      "1225:\tlearn: 0.2204610\ttest: 0.7572279\tbest: 0.7569546 (1210)\ttotal: 2m 11s\tremaining: 12m 5s\n",
      "1250:\tlearn: 0.2173720\ttest: 0.7574638\tbest: 0.7569546 (1210)\ttotal: 2m 14s\tremaining: 12m 5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7569545549\n",
      "bestIteration = 1210\n",
      "\n",
      "Shrink model to first 1211 iterations.\n"
     ]
    }
   ],
   "source": [
    "from utils import train_classifier\n",
    "\n",
    "custom_model, report = train_classifier(encodings, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "              beet       0.65      0.69      0.67       573\n",
      "             maize       0.93      0.89      0.91      6083\n",
      "             other       0.62      0.68      0.65      1444\n",
      "          potatoes       0.74      0.75      0.74      1449\n",
      "unspecified_barley       0.58      0.58      0.58       510\n",
      " unspecified_wheat       0.79      0.82      0.80      1699\n",
      "\n",
      "          accuracy                           0.81     11758\n",
      "         macro avg       0.72      0.73      0.73     11758\n",
      "      weighted avg       0.82      0.81      0.82     11758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[Deploy custom model](#toc0_)\n",
    "\n",
    "Once trained, we have to upload our model to the cloud so it can be used for inference. Executing the cell below will require you to enter a `token`. A WorldCereal admin has to provide this token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading model to `demo_large_20240709155441_custommodel.onnx`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 42.3M    0     0  100 42.3M      0  11.5M  0:00:03  0:00:03 --:--:-- 11.5M"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed to: https://artifactory.vgt.vito.be/artifactory/worldcereal_models/demo_large_20240709155441_custommodel.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100 42.3M    0   812  100 42.3M    207  10.8M  0:00:03  0:00:03 --:--:-- 10.8M\n"
     ]
    }
   ],
   "source": [
    "from utils import deploy_model\n",
    "\n",
    "model_url = deploy_model(custom_model, pattern=\"demo_large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[Generate a map](#toc0_)\n",
    "\n",
    "Using our custom model, we generate a map for our region of interest and download the result.\n",
    "\n",
    "You can also manually download the resulting GeoTIFF by clicking on the link that will be diplayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openeo.rest.connection:Found OIDC providers: ['CDSE']\n",
      "INFO:openeo.rest.connection:No OIDC provider given, but only one available: 'CDSE'. Using that one.\n",
      "INFO:openeo.rest.connection:Using default client_id 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e' from OIDC provider 'CDSE' info.\n",
      "INFO:openeo.rest.connection:Found refresh token: trying refresh token based authentication.\n",
      "INFO:openeo.rest.auth.oidc:Doing 'refresh_token' token request 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' with post data fields ['grant_type', 'client_id', 'refresh_token'] (client_id 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e')\n",
      "INFO:openeo.rest.connection:Obtained tokens: ['access_token', 'id_token', 'refresh_token']\n",
      "INFO:openeo.rest.auth.config:Storing refresh token for issuer 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE' (client 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n",
      "Selected orbit direction: DESCENDING from max accumulated area overlap between bounds and products.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:PrestoFeatureExtractor:No additional dependencies are defined. If you wish to add dependencies to your feature extractor, override the `dependencies` method in your class.\n",
      "WARNING:PrestoFeatureExtractor:No additional dependencies are defined. If you wish to add dependencies to your feature extractor, override the `dependencies` method in your class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-240709923b394dfaa57d04dfa7aacee3': send 'start'\n",
      "0:00:16 Job 'j-240709923b394dfaa57d04dfa7aacee3': created (progress 0%)\n",
      "0:00:26 Job 'j-240709923b394dfaa57d04dfa7aacee3': created (progress 0%)\n",
      "0:00:32 Job 'j-240709923b394dfaa57d04dfa7aacee3': created (progress 0%)\n",
      "0:00:47 Job 'j-240709923b394dfaa57d04dfa7aacee3': created (progress 0%)\n",
      "0:00:57 Job 'j-240709923b394dfaa57d04dfa7aacee3': created (progress 0%)\n",
      "0:01:12 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:01:28 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:01:47 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:02:11 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:02:41 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:03:19 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:04:06 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:05:04 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:06:05 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:07:05 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:08:05 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:09:06 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:10:06 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:11:06 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:12:07 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:13:10 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:14:11 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:15:11 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:16:12 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:17:12 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:18:21 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:19:21 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:20:21 Job 'j-240709923b394dfaa57d04dfa7aacee3': running (progress N/A)\n",
      "0:21:22 Job 'j-240709923b394dfaa57d04dfa7aacee3': finished (progress 100%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openeo.rest.job:Downloading Job result asset 'openEO_2020-01-01Z.tif' from https://openeo.creo.vito.be/openeo/jobs/j-240709923b394dfaa57d04dfa7aacee3/results/assets/NGZkOWRiOTYtZDYyMC00NDU0LTliZTYtMTRhN2Q4ZTkyMzU3/ba0b5b0b6f0c2e76f004c79495de9329/openEO_2020-01-01Z.tif?expires=1721139745 to cropmap.tif\n"
     ]
    }
   ],
   "source": [
    "from worldcereal.job import WorldCerealProduct, generate_map, CropTypeParameters\n",
    "from openeo_gfmap import TemporalContext\n",
    "\n",
    "# Set temporal range to generate product\n",
    "temporal_extent = TemporalContext(\n",
    "    start_date=\"2021-11-01\",\n",
    "    end_date=\"2022-10-31\",\n",
    ")\n",
    "\n",
    "# Initializes default parameters\n",
    "parameters = CropTypeParameters()\n",
    "\n",
    "# Change the URL to the classification model\n",
    "parameters.classifier_parameters.classifier_url = model_url\n",
    "\n",
    "# Launch the job\n",
    "job_results = generate_map(\n",
    "    spatial_extent,\n",
    "    temporal_extent,\n",
    "    output_path=\"./cropmap.tif\",\n",
    "    product_type=WorldCerealProduct.CROPTYPE,\n",
    "    croptype_parameters=parameters,\n",
    "    out_format=\"GTiff\",\n",
    "    tile_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For interpreting your raster, the following information is useful:\n",
    "- Band 1 contains the class integers and by executing the cell below you can check which integer belongs to which crop type\n",
    "- Band 2 contains the probability associated to the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster value - Class name\n",
      "0 -> beet\n",
      "1 -> maize\n",
      "2 -> other\n",
      "3 -> potatoes\n",
      "4 -> unspecified_barley\n",
      "5 -> unspecified_wheat\n"
     ]
    }
   ],
   "source": [
    "LUT = {class_int: class_name for class_int, class_name in enumerate(custom_model.get_params()['class_names'])}\n",
    "print('Raster value - Class name')\n",
    "for key, value in LUT.items():\n",
    "    print(f\"{key} -> {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
